{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denison CS181/DA210 SW Lab #9 - Step 1\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. This is a combination of **restarting the kernel** and then **running all cells** (in the menubar, select Kernel$\\rightarrow$Restart And Run All).\n",
    "\n",
    "Make sure you fill in any place that says `# YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84497297e822c3a354377d3b8e151006",
     "grade": false,
     "grade_id": "cell-b9abcf27cf7faf8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from 'C:\\\\Users\\\\Hudson Pham\\\\Documents\\\\school\\\\denison sophomore\\\\CS181\\\\cs181-f22\\\\modules\\\\util.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import requests\n",
    "from IPython.display import Image\n",
    "\n",
    "htmlparser =  etree.HTMLParser()\n",
    "\n",
    "module_dir = os.path.join(\"..\", \"..\", \"modules\")\n",
    "module_path = os.path.abspath(module_dir)\n",
    "if not module_path in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import util\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A: HTML structure\n",
    "\n",
    "Although we will typically assume that HTML is properly formatted, that is no guarantee when using real websites, as they may have been created without (or before) such assumptions.\n",
    "\n",
    "For example, consider the following string: `\"<html><head><title>test<body><h1>header title</h3>\"`.  This is \"bad\" for several reasons:\n",
    "\n",
    "* The `<html>`, `<head>`, `<title>`, and `<body>` tags are all missing a closing tag.\n",
    "* The `<h1>` header tag is closed with a `<h3>` tag.\n",
    "\n",
    "If we try to use an XML parser, this will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse as XML\n"
     ]
    }
   ],
   "source": [
    "# Broken HTML: <html>, <head>, <title>, <body> not closed, <h1> closed as <h3>\n",
    "bad_html = \"<html><head><title>test<body><h1>header title</h3>\"\n",
    "\n",
    "# Try and fail to parse as XML\n",
    "xmlparser = etree.XMLParser()\n",
    "try:\n",
    "    tree = etree.parse(io.StringIO(bad_html), parser=xmlparser)\n",
    "    util.print_xml(tree.getroot())\n",
    "except:\n",
    "    # Should end up here\n",
    "    print(\"Failed to parse as XML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can instead use a HTML parser provided by `etree`, which can handle such messy HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>\n",
      "    <title>test</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>header title</h1>\n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Try again as HTML\n",
    "htmlparser = etree.HTMLParser()\n",
    "try:\n",
    "    # This one should work\n",
    "    tree = etree.parse(io.StringIO(bad_html), parser=htmlparser)\n",
    "    util.print_xml(tree.getroot())\n",
    "except:\n",
    "    print(\"Failed to parse as HTML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider well-formed HTML.  As XML, it must have a single root node.  For HTML documents, this should be `<html>`.  This node should have, at most, one `<head>` child and one `<body>` child, in that order.\n",
    "\n",
    "The `<head>` node contains meta information about the HTML document.  A common part of this is the webpage title, using the `<title>` tag.\n",
    "\n",
    "The `<body>` node contains the content of the webpage.  This can include text nodes (e.g., using `<div>`, `<p>`, and `<span>`), headers (`<h1>` through `<h6>`), links (`<a>`), lists (`<ul>` or `<ol>`) and tables (`<table>`).\n",
    "\n",
    "Here is a simple example (which we can parse as either XML or HTML, as it is properly formed XML):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>\n",
      "    <title>test</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>header title</h1>\n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# A simple HTML string\n",
    "simple_html = \"<html><head><title>test</title></head><body><h1>header title</h1></body></html>\"\n",
    "tree = etree.parse(io.StringIO(simple_html), parser=xmlparser)\n",
    "\n",
    "# Display the HTML\n",
    "util.print_xml(tree.getroot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part B: Web scraping - data acquisition\n",
    "\n",
    "We can either work with locally saved HTML documents, or download them from the web.  We won't focus on this for now, so the code in the following cell doesn't need to make too much sense to you yet (see Chapters 18-21 for what we've skipped so far in this regard if you're curious).\n",
    "\n",
    "#### Scraping via GET request\n",
    "\n",
    "At a high level, we can use a _URL_ to access a document on the web, and form a _request_ to _get_ the content at that URL.  If the _response_ has _status_ `200`, then the request was successful.\n",
    "\n",
    "In this case, we will download the HTML source of the page: [http://datasystems.denison.edu/basic.html](http://datasystems.denison.edu/basic.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "  <head>\n",
      "    <title>Data Systems Basic HTML Page</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>First Level Heading</h1>\n",
      "\n",
      "    <p>Paragraph defined in <b>body</b>.\n",
      "\n",
      "    <h2>Second Level Heading</h2>\n",
      "\n",
      "    <a href=\"http://docs.python.org\">Link</a> to Python documentation.\n",
      "    </p>\n",
      "\n",
      "    <ul>\n",
      "      <li>Item 1\n",
      "      <ol>\n",
      "        <li>Item 1 nested</li>\n",
      "        <li>Item 2 nested</li>\n",
      "      </ol>\n",
      "      </li>\n",
      "      <li>Item 2</li>\n",
      "      <li>Item 3</li>\n",
      "    </ul>\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download HTML from a web URL\n",
    "\n",
    "location = \"datasystems.denison.edu\"\n",
    "resource = \"/basic.html\"\n",
    "\n",
    "url = util.buildURL(resource, location)\n",
    "response = requests.get(url)\n",
    "assert response.status_code == 200\n",
    "\n",
    "# Display the retrieved HTML text\n",
    "basic_html = response.text\n",
    "print(basic_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this webpage is slightly more complex than our previous simple example: it has a nested list, with the outer list being unordered (bullet points), and the inner list being ordered (numbered).\n",
    "\n",
    "It also contains two heading levels, as well as bolded text and a link inside of a paragraph node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping via `curl`\n",
    "\n",
    "Alternatively, we can use the `curl` command (a command-line tool, not part of Python itself) to download the webpage content to a local HTML file.  The following command will save the HTML source of [http://datasystems.denison.edu/basic.html](http://datasystems.denison.edu/basic.html) to your computer, in a file `basic.html` in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the HTML to a file -- do not modify this!\n",
    "!curl -s -o basic.html http://datasystems.denison.edu/basic.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part C: Web Scraping a Wikipedia Table\n",
    "\n",
    "Consider the Wikipedia page of Municipalities in Ohio: https://en.wikipedia.org/wiki/List_of_municipalities_in_Ohio.  A simpler version of this page can be found using the Wikipedia API: https://en.wikipedia.org/api/rest_v1/page/html/List_of_municipalities_in_Ohio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discovery\n",
    "\n",
    "Go to the above web page using Chrome, navigate to View->Developer->Inspect Elements, or in Firefox, Tools->Browser Tools->Web Developer Tools.\n",
    "\n",
    "You do not have to submit the sketches mentioned below, but the following steps walk you through the discovery process.\n",
    "\n",
    "1. Find where in the HTML the table exists.\n",
    "2. Sketch the HTML subtree starting at that point (not all nodes, but at least 2 rows of data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the first checkpoint in the lab.  Make sure to have it signed off by the instructor.\n",
    ">\n",
    "> Checkpoint 1: Either procedurally or using XPath, how could you determine how many data rows are in this table, if you had a variable `table_node` that gives the node at the root of this subtree (e.g., with `tag` `\"table\"`)?\n",
    ">\n",
    "> Note: You don't have to write the code for this question -- that comes next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Setup\n",
    "\n",
    "As mentioned earlier, you do not need to understand anything from the next code cell that you haven't already seen.  We'll learn more about web requests in Unit 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS\n",
    "\n",
    "# Read HTML from the web\n",
    "resource_path = \"/api/rest_v1/page/html/List_of_municipalities_in_Ohio\"\n",
    "\n",
    "url = util.buildURL(resource_path, \"en.wikipedia.org\")\n",
    "response = requests.get(url)\n",
    "assert response.status_code == 200\n",
    "\n",
    "# Use a custom HTML parser to parse the response content into an XML Element\n",
    "tree = etree.parse(io.BytesIO(response.content), htmlparser)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Acquisition\n",
    "\n",
    "**Q1:** Either procedurally or using XPath, find the node with `tag` `\"table\"` that represents the root of the subtree for this table.  Assign the node to the variable `tableroot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d42fad427f0ca99e5fe9a686f69c88f",
     "grade": true,
     "grade_id": "cell-31ccac71984445de",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class='wikitable sortable mw-collapsible' id='mwWQ'>\n",
      "  <tbody id='mwWg'>\n",
      "    <tr id='mwWw'>\n",
      "      <th id='mwXA'>Name</th>\n",
      "      <th id='mwXQ'>Class</th>\n",
      "      <th id='mwXg'>Population (2020)\n",
      "        <sup ...>\n",
      "          <a href='./List_of_municipalities_in_Ohio#cite_no\n",
      "            <span ...>[2]</span>\n",
      "          </a>\n",
      "        </sup>\n",
      "      </th>\n",
      "      <th id='mwYQ'>Population (2010)\n",
      "        <sup ...>\n",
      "          <a href='./List_of_municipalities_in_Ohio#cite_no\n",
      "            <span ...>[3]</span>\n",
      "          </a>\n",
      "        </sup>\n",
      "      </th>\n",
      "      <th id='mwZA'>County</th>\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "tableroot = root.xpath(\"//table\")[0]\n",
    "\n",
    "# Display the first 20 lines of the tree\n",
    "util.print_xml(tableroot, depth=16, nlines=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert tableroot.tag == \"table\"\n",
    "assert tableroot.get(\"class\") == \"wikitable sortable mw-collapsible\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Use the result of `print_xml` from Question 1 to make sure your understanding of the `table` tree matches your hand-drawn tree from earlier.  If you chose to start from `root`, would your expression be **guaranteed** to get the table you are interested in?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the same. We have \"root.xpath()\" and \"root\" is already the tree's root, so it is no different whether we use \".//table\" or \"//table\" inside \"root.xpath(<>)\", "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Extract the column names from the table, and store the list in a variable `col_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5404f81d8e996f298216cc88adf0e9f2",
     "grade": true,
     "grade_id": "cell-68a4cd2c00d8a69f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Class', 'Population (2020)', 'Population (2010)', 'County']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "col_names = tableroot.xpath(\".//th/text()\")\n",
    "\n",
    "# Print the list of column names\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert type(col_names) is list\n",
    "assert len(col_names) == 5\n",
    "assert \"Population (2020)\" in col_names\n",
    "assert \"County\" in col_names\n",
    "assert \"Population (2020)[2]\" not in col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the second checkpoint in the lab.  Make sure to have it signed off by the instructor.\n",
    ">\n",
    "> Checkpoint 2: In general, you have two choices for scraping the data in this table: you can either acquire all data in a single big list and split it into a _list of lists_, or you can acquire each column individually and store the data in a _dictionary of lists_.\n",
    ">\n",
    "> Looking at the HTML and/or the web page, why would it be challenging to build an LoL for this table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programmatic Extraction: Dictionary of Column Lists\n",
    "\n",
    "A perhaps simpler solution involves using the regularity of the columns in a table (be it in HTML or other regular table form).  Within each `tr`, the **position** of each of the `td` elements for the five fields in this table is always the same, regardless of row.  So at position 1 within all the rows, we always have the `Name`, at position 2, we always have the `Class`, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Scrape the municipality names from the first column of the table.  Assign the result to the variable `names_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "267f3b58a2d62fccab066fa843b340e0",
     "grade": true,
     "grade_id": "cell-df631f45510f24ea",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926\n",
      "Name list prefix: ['Akron', 'Alliance', 'Amherst', 'Ashland', 'Ashtabula', 'Athens', 'Aurora', 'Avon', 'Avon Lake', 'Barberton']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "names_list = tableroot.xpath(\".//td[position()=1]/a/text()\")\n",
    "\n",
    "# Print info about the year vector\n",
    "print(len(names_list))\n",
    "print(\"Name list prefix:\", names_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert type(names_list) is list\n",
    "assert len(names_list) == 926\n",
    "assert names_list[0] == \"Akron\"\n",
    "assert names_list[-1] == \"Zoar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** For the `Class` and population columns, we could do this three times, with different values for the position, creating three separate lists.  Instead, we want to use Python string formatting to dynamically create an xpath query that retrieves the `td` at a position given by a variable, and then traverses to the text attribute.\n",
    "\n",
    "Assign to `xs_template_q5` a Python string using `{}` in place of the position from your solution above, so that the testing code shows its use by obtaining data columns from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c2376ae8d382c4177f0a4fc79448a24",
     "grade": true,
     "grade_id": "cell-2dba3d6ffed57fcb",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['City', 'City', 'City', 'City', 'City', 'City', 'City', 'City']\n",
      "['190,469', '21,672', '12,681', '19,225', '17,975', '23,849', '17,239', '24,847']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "xs_template_q5 = \".//td[position()={}]/text()\"\n",
    "\n",
    "# Test your template, retrieving two of the column vectors\n",
    "classes = tableroot.xpath(xs_template_q5.format(2))\n",
    "print(classes[:8])\n",
    "pop2020 = tableroot.xpath(xs_template_q5.format(3))\n",
    "print(pop2020[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert type(xs_template_q5) is str\n",
    "assert \"pineapple\" in xs_template_q5.format(\"pineapple\")\n",
    "assert len(classes) == 926\n",
    "assert len(pop2020) == 926\n",
    "assert classes[-1] == \"Village\"\n",
    "assert pop2020[3] == \"19,225\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:** The format string you defined in the previous question doesn't work with the last column.  Write another format string that returns only the first `County` listed for each municipality (e.g., only `\"Stark\"` for `\"Alliance\"`).\n",
    "\n",
    "Assign your string to `xs_q6`.  You can hard-code the column number, so you don't need `{}` in your string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Summit', 'Stark', 'Lorain', 'Ashland', 'Ashtabula', 'Athens', 'Portage', 'Lorain']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "xs_q6 = \".//td[position()=5]/a[position()=1]/text()\"\n",
    "\n",
    "# Test your template, retrieving two of the four column vectors\n",
    "counties = tableroot.xpath(xs_q6)\n",
    "print(counties[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert type(xs_q6) is str\n",
    "assert len(counties) == 926\n",
    "assert counties[0] == \"Summit\"\n",
    "assert counties[1] == \"Stark\"\n",
    "assert counties[2] == \"Lorain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7:** Using the results from the previous questions, or any other approach you choose, build a DoL representing this table.  The dictionary keys should be column names, and the value lists should contain the per-column table data.  Note that you only need the first `County` listed for any given municipality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29675f815f0f3ca01b108d1703cfa952",
     "grade": true,
     "grade_id": "cell-3f2c606502df2603",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'County', 'Population (2020)', 'Population (2021)', 'Class']\n",
      "['Akron', 'Summit', '190,469', '198,090', 'City']\n",
      "['Alliance', 'Stark', '21,672', '21,616', 'City']\n",
      "['Amherst', 'Lorain', '12,681', '12,021', 'City']\n",
      "['Ashland', 'Ashland', '19,225', '20,423', 'City']\n",
      "['Ashtabula', 'Ashtabula', '17,975', '18,079', 'City']\n",
      "['Athens', 'Athens', '23,849', '24,688', 'City']\n",
      "['Aurora', 'Portage', '17,239', '16,230', 'City']\n",
      "['Avon', 'Lorain', '24,847', '23,263', 'City']\n",
      "['Avon Lake', 'Lorain', '25,206', '24,391', 'City']\n",
      "['Barberton', 'Summit', '25,191', '26,072', 'City']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "pop2021 = tableroot.xpath(xs_template_q5.format(4))\n",
    "DoL = {\n",
    "    \"Name\": names_list,\n",
    "    \"County\": counties,\n",
    "    \"Population (2020)\": pop2020,\n",
    "    \"Population (2021)\": pop2021,\n",
    "    \"Class\": classes,\n",
    "}\n",
    "\n",
    "# Print the first ten rows of the resulting DoL\n",
    "print(list(DoL.keys()))\n",
    "for rowid in range(10):\n",
    "    print([DoL[col][rowid] for col in DoL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>County</th>\n",
       "      <th>Population (2020)</th>\n",
       "      <th>Population (2021)</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akron</td>\n",
       "      <td>Summit</td>\n",
       "      <td>190,469</td>\n",
       "      <td>198,090</td>\n",
       "      <td>City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alliance</td>\n",
       "      <td>Stark</td>\n",
       "      <td>21,672</td>\n",
       "      <td>21,616</td>\n",
       "      <td>City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amherst</td>\n",
       "      <td>Lorain</td>\n",
       "      <td>12,681</td>\n",
       "      <td>12,021</td>\n",
       "      <td>City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashland</td>\n",
       "      <td>Ashland</td>\n",
       "      <td>19,225</td>\n",
       "      <td>20,423</td>\n",
       "      <td>City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ashtabula</td>\n",
       "      <td>Ashtabula</td>\n",
       "      <td>17,975</td>\n",
       "      <td>18,079</td>\n",
       "      <td>City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>Yorkshire</td>\n",
       "      <td>Darke</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>Yorkville</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>968</td>\n",
       "      <td>1,079</td>\n",
       "      <td>Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>Zaleski</td>\n",
       "      <td>Vinton</td>\n",
       "      <td>230</td>\n",
       "      <td>278</td>\n",
       "      <td>Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Zanesfield</td>\n",
       "      <td>Logan</td>\n",
       "      <td>194</td>\n",
       "      <td>197</td>\n",
       "      <td>Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>Zoar</td>\n",
       "      <td>Tuscarawas</td>\n",
       "      <td>172</td>\n",
       "      <td>169</td>\n",
       "      <td>Village</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>926 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name      County Population (2020) Population (2021)    Class\n",
       "0         Akron      Summit           190,469           198,090     City\n",
       "1      Alliance       Stark            21,672            21,616     City\n",
       "2       Amherst      Lorain            12,681            12,021     City\n",
       "3       Ashland     Ashland            19,225            20,423     City\n",
       "4     Ashtabula   Ashtabula            17,975            18,079     City\n",
       "..          ...         ...               ...               ...      ...\n",
       "921   Yorkshire       Darke                95                96  Village\n",
       "922   Yorkville   Jefferson               968             1,079  Village\n",
       "923     Zaleski      Vinton               230               278  Village\n",
       "924  Zanesfield       Logan               194               197  Village\n",
       "925        Zoar  Tuscarawas               172               169  Village\n",
       "\n",
       "[926 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging cell -- try to make a DataFrame\n",
    "pd.DataFrame(DoL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert type(DoL) is dict\n",
    "assert type(DoL[\"Name\"]) is list\n",
    "assert len(DoL[\"County\"]) == 926\n",
    "assert DoL[\"Name\"][0] == \"Akron\"\n",
    "assert DoL[\"Population (2020)\"][1] == \"21,672\"\n",
    "assert DoL[\"County\"][1] == \"Stark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the third (and final) checkpoint in the lab.  Make sure to have it signed off by the instructor.\n",
    ">\n",
    "> Checkpoint 3: How could you modify your scraping of the last column to retrieve a list of `County` values for each municipality, rather than just the first listed?\n",
    ">\n",
    "> (Note: You don't have to actually code this, just think about it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Part D\n",
    "\n",
    "How much time (in minutes/hours) did you spend on this lab outside of class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For about 30 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
